{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41aa3f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import http.client\n",
    "import requests\n",
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "from collections import defaultdict\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ceb706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_info(data):\n",
    "    \"\"\"\n",
    "    Parse the API response data (assumed to be JSON) and extract book metadata.\n",
    "\n",
    "    Args:\n",
    "        data (str): JSON string from the API response.\n",
    "\n",
    "    Returns:\n",
    "        list: List of dictionaries containing book metadata.\n",
    "    \"\"\"\n",
    "    books = json.loads(data)\n",
    "\n",
    "    # If books is a dict with a key like 'results', use that\n",
    "    if isinstance(books, dict) and 'results' in books:\n",
    "        books = books['results']\n",
    "\n",
    "    # Collect id, title, authors, subjects, and bookshelves for each book\n",
    "    book_info = []\n",
    "    for book in books:\n",
    "        book_id = book.get('id')\n",
    "        title = book.get('title')\n",
    "        authors = [author.get('name') for author in book.get('authors', [])]\n",
    "        subjects = book.get('subjects', [])\n",
    "        bookshelves = book.get('bookshelves', [])\n",
    "        book_info.append({\n",
    "            'id': book_id,\n",
    "            'title': title,\n",
    "            'authors': authors,\n",
    "            'subjects': subjects,\n",
    "            'bookshelves': bookshelves\n",
    "        })\n",
    "    return book_info\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd05d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_and_index_books(book_info, conn, headers, stop_words):\n",
    "    \"\"\"\n",
    "    For each book in book_info, fetch the text, print a sample, and build an inverted index (excluding stop words).\n",
    "\n",
    "    Args:\n",
    "        book_info (list): List of book metadata dictionaries.\n",
    "        conn (http.client.HTTPSConnection): HTTP connection object.\n",
    "        headers (dict): Headers for the API request.\n",
    "        stop_words (set): Set of stop words to exclude from the index.\n",
    "\n",
    "    Returns:\n",
    "        dict: Inverted index mapping words to lists of book IDs.\n",
    "    \"\"\"\n",
    "    inverted_index = defaultdict(list)\n",
    "    for book in book_info:\n",
    "        book_id = book['id']\n",
    "        response = requests.get(f\"https://project-gutenberg-free-books-api1.p.rapidapi.com/books/{book_id}/text?cleaning_mode=simple\", headers=headers)\n",
    "        text = response.text\n",
    "        \n",
    "        for word in text.split():\n",
    "            word = word.lower().strip('.,!?;\"()[]{}')\n",
    "            if word and word not in stop_words:\n",
    "                if book_id not in inverted_index[word]:\n",
    "                    inverted_index[word][book_id] = 0\n",
    "            inverted_index[word][book_id] += 1\n",
    "    return inverted_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9f0bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_fetch_and_store_books(data, conn, headers, datalake_dir='datalake'):\n",
    "    \"\"\"\n",
    "    Extract book metadata, fetch book texts, and store metadata in a structured datalake directory.\n",
    "\n",
    "    Args:\n",
    "        data (str): JSON string from the API response.\n",
    "        conn (http.client.HTTPSConnection): HTTP connection object.\n",
    "        headers (dict): Headers for the API request.\n",
    "        datalake_dir (str): Root directory for storing data.\n",
    "    Returns:\n",
    "        list: List of book metadata dictionaries.\n",
    "    \"\"\"\n",
    "    # Extract metadata\n",
    "    book_info = extract_book_info(data)\n",
    "\n",
    "    # Create datalake directory structure\n",
    "    now = datetime.now()\n",
    "    date_dir = now.strftime('%Y-%m-%d')\n",
    "    time_dir = now.strftime('%H')\n",
    "    full_path = os.path.join(datalake_dir, date_dir, time_dir)\n",
    "    os.makedirs(full_path, exist_ok=True)\n",
    "\n",
    "    # For each book, save metadata and text in separate files\n",
    "    for book in book_info:\n",
    "        book_id = book['id']\n",
    "        # Save metadata as [book_id].header.txt\n",
    "        header_path = os.path.join(full_path, f\"{book_id}.header.txt\")\n",
    "        with open(header_path, 'w', encoding='utf-8') as header_file:\n",
    "            json.dump(book, header_file, ensure_ascii=False, indent=4)\n",
    "        # Fetch and save book text as [book_id].body.txt\n",
    "        response = requests.get(f\"https://project-gutenberg-free-books-api1.p.rapidapi.com/books/{book_id}/text?cleaning_mode=simple\", headers=headers)\n",
    "        text = response.text\n",
    "        book_text = json.loads(text).get('text', '')\n",
    "        body_path = os.path.join(full_path, f\"{book_id}.body.txt\")\n",
    "        with open(body_path, 'w', encoding='utf-8') as body_file:\n",
    "            body_file.write(book_text)\n",
    "\n",
    "    return book_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "639e9780",
   "metadata": {},
   "outputs": [],
   "source": [
    "def datamart_creation(book_info, conn, headers, stop_words):\n",
    "    \"\"\"\n",
    "    Create a datamart by processing the stored book metadata and texts.\n",
    "\n",
    "    This function creates a directory named 'datamart', if it doesn't already exist, \n",
    "    and processes the data stored in the 'datalake' directory. Inside datamart create two files,\n",
    "    unless they already exist: metadata.sql and inverted_index.json\n",
    "\n",
    "    Args:\n",
    "        book_info (list): List of book metadata dictionaries.\n",
    "        conn (http.client.HTTPSConnection): HTTP connection object.\n",
    "        headers (dict): Headers for the API request.\n",
    "        stop_words (set): Set of stop words to exclude from the index.\n",
    "    \"\"\"\n",
    "    datamart_dir = 'datamart'\n",
    "    os.makedirs(datamart_dir, exist_ok=True)\n",
    "\n",
    "    metadata_path = os.path.join(datamart_dir, 'metadata.sql')\n",
    "    inverted_index_path = os.path.join(datamart_dir, 'inverted_index.json')\n",
    "    inverted_index = fetch_and_index_books(book_info, conn, headers, stop_words)\n",
    "\n",
    "    if not os.path.exists(metadata_path) or not os.path.exists(inverted_index_path):\n",
    "        # Process datalake to create metadata.sql and inverted_index.json\n",
    "        datalake_dir = 'datalake'\n",
    "        metadata = []\n",
    "        for root, files in os.walk(datalake_dir):\n",
    "            for file in files:\n",
    "                if file.endswith('.header.txt'):\n",
    "                    with open(os.path.join(root, file), 'r', encoding='utf-8') as f:\n",
    "                        book_metadata = json.load(f)\n",
    "                        metadata.append(book_metadata)\n",
    "\n",
    "        # Create inverted index file\n",
    "        with open(inverted_index_path, 'w', encoding='utf-8') as index_file:\n",
    "            json.dump(inverted_index, index_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "        # Save metadata to SQL file\n",
    "        with open(metadata_path, 'w', encoding='utf-8') as sql_file:\n",
    "            # Create table statement (adjust columns as per metadata structure)\n",
    "            sql_file.write(\n",
    "            \"CREATE TABLE IF NOT EXISTS books (\\n\"\n",
    "            \"    id INTEGER PRIMARY KEY,\\n\"\n",
    "            \"    title TEXT,\\n\"\n",
    "            \"    authors TEXT,\\n\"\n",
    "            \"    subjects TEXT,\\n\"\n",
    "            \"    bookshelves TEXT\\n\"\n",
    "            \");\\n\\n\"\n",
    "            )\n",
    "            # Insert statements\n",
    "            for book in metadata:\n",
    "                authors = ', '.join(book.get('authors', []))\n",
    "                subjects = ', '.join(book.get('subjects', []))\n",
    "                bookshelves = ', '.join(book.get('bookshelves', []))\n",
    "                # Escape single quotes in text fields\n",
    "                title = book.get('title', '').replace(\"'\", \"''\")\n",
    "                authors = authors.replace(\"'\", \"''\")\n",
    "                subjects = subjects.replace(\"'\", \"''\")\n",
    "                bookshelves = bookshelves.replace(\"'\", \"''\")\n",
    "                sql_file.write(\n",
    "                    f\"INSERT INTO books (id, title, authors, subjects, bookshelves) VALUES \"\n",
    "                    f\"({book.get('id')}, '{title}', '{authors}', '{subjects}', '{bookshelves}');\\n\"\n",
    "                    )\n",
    "\n",
    "        # Save inverted index to JSON\n",
    "        with open(inverted_index_path, 'w', encoding='utf-8') as index_file:\n",
    "            json.dump(inverted_index, index_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233cbf87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def controller(data):\n",
    "    \"\"\"Controller function to control which books are downloaded \n",
    "    and which ones are indexed, creating in the directory control\n",
    "    the files downloaded_books.txt and indexed_books.txt.\"\"\"\n",
    "    \n",
    "    control_dir = 'control'\n",
    "    os.makedirs(control_dir, exist_ok=True)\n",
    "    downloaded_books_path = os.path.join(control_dir, 'downloaded_books.txt')\n",
    "    indexed_books_path = os.path.join(control_dir, 'indexed_books.txt')\n",
    "\n",
    "    conn = http.client.HTTPSConnection(\"project-gutenberg-free-books-api1.p.rapidapi.com\")\n",
    "    \n",
    "    headers = {\n",
    "        'x-rapidapi-key': \"29ab1edf9dmshb37d07ffbb17e29p1ce99ejsn7592f187c027\",\n",
    "        'x-rapidapi-host': \"project-gutenberg-free-books-api1.p.rapidapi.com\"\n",
    "    }\n",
    "        \n",
    "    nltk.download('stopwords')\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Call the functions to download and index books\n",
    "    book_info = extract_fetch_and_store_books(data.decode(\"utf-8\"), conn, headers)\n",
    "    \n",
    "    # Update downloaded_books.txt\n",
    "    with open(downloaded_books_path, 'w', encoding='utf-8') as f:\n",
    "        for book in book_info:\n",
    "            f.write(f\"{book['id']}\\n\")\n",
    "\n",
    "    datamart_creation(book_info, conn, headers, stop_words)\n",
    "\n",
    "    # Update indexed_books.txt\n",
    "    with open(indexed_books_path, 'w', encoding='utf-8') as f:\n",
    "        for book in book_info:\n",
    "            f.write(f\"{book['id']}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e680ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(url = \"https://project-gutenberg-free-books-api1.p.rapidapi.com/books\"):\n",
    "    headers = {\n",
    "        \"x-rapidapi-key\": \"29ab1edf9dmshb37d07ffbb17e29p1ce99ejsn7592f187c027\",\n",
    "\t    \"x-rapidapi-host\": \"project-gutenberg-free-books-api1.p.rapidapi.com\"\n",
    "        }\n",
    "\n",
    "    response = requests.get(url, headers=headers)\n",
    "\n",
    "    controller(response.content)\n",
    "\n",
    "    # from response use next to get next page\n",
    "    url = response.json().get('next')\n",
    "    if url == \"https://project-gutenberg-free-books-api1.p.rapidapi.com/books?page=21\":\n",
    "        return \"Frist 20 pages done\"\n",
    "    else:\n",
    "        main(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93338d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
